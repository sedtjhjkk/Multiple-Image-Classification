{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1da19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd88c1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531b1ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\agniv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4dc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ff7021a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('seg_train/',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843c29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "893c2dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('seg_test/',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1acccc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e09d0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e950fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0deb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "639e82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a0951b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87dba6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06beb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "439/439 [==============================] - 60s 136ms/step - loss: 1.0125 - accuracy: 0.6077 - val_loss: 0.8887 - val_accuracy: 0.6767\n",
      "Epoch 2/8\n",
      "439/439 [==============================] - 53s 122ms/step - loss: 0.7715 - accuracy: 0.7129 - val_loss: 0.6663 - val_accuracy: 0.7613\n",
      "Epoch 3/8\n",
      "439/439 [==============================] - 53s 122ms/step - loss: 0.6761 - accuracy: 0.7535 - val_loss: 0.6789 - val_accuracy: 0.7537\n",
      "Epoch 4/8\n",
      "439/439 [==============================] - 54s 122ms/step - loss: 0.6120 - accuracy: 0.7775 - val_loss: 0.6043 - val_accuracy: 0.7870\n",
      "Epoch 5/8\n",
      "439/439 [==============================] - 54s 123ms/step - loss: 0.5622 - accuracy: 0.7949 - val_loss: 0.5704 - val_accuracy: 0.8043\n",
      "Epoch 6/8\n",
      "439/439 [==============================] - 55s 124ms/step - loss: 0.5335 - accuracy: 0.8071 - val_loss: 0.6322 - val_accuracy: 0.7813\n",
      "Epoch 7/8\n",
      "439/439 [==============================] - 56s 128ms/step - loss: 0.5034 - accuracy: 0.8182 - val_loss: 0.5670 - val_accuracy: 0.8040\n",
      "Epoch 8/8\n",
      "439/439 [==============================] - 62s 142ms/step - loss: 0.4765 - accuracy: 0.8261 - val_loss: 0.5549 - val_accuracy: 0.8137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22477ae74f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06bf2b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\agniv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7a9ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = tf.keras.utils.load_img('istock-000052189572-small-8d0ee3f3fc3c8d71e15deead6e188e5a.webp', target_size = (64, 64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd012ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40cb4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'buildings_train': 0,\n",
       " 'forest_train': 1,\n",
       " 'glacier_train': 2,\n",
       " 'mountain_train': 3,\n",
       " 'sea_train': 4,\n",
       " 'street_train': 5}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c2b96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a863678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0 \n",
    "\n",
    "for i in range(6):\n",
    "    if result[0][i] == 1:\n",
    "        j = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad0fbe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glacier\n"
     ]
    }
   ],
   "source": [
    "if j == 0:\n",
    "    print(\"buildings\")\n",
    "\n",
    "elif j == 1:\n",
    "    print(\"forest\")\n",
    "    \n",
    "elif j == 2:\n",
    "    print(\"glacier\")\n",
    "    \n",
    "elif j == 3:\n",
    "    print(\"mountain\")\n",
    "    \n",
    "elif j == 4:\n",
    "    print(\"sea\")\n",
    "    \n",
    "else:\n",
    "    print(\"street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d022e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
